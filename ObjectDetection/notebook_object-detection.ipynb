{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.10.12 torch-2.0.1+cu117 CUDA:0 (NVIDIA A30, 24060MiB)\n",
      "Setup complete âœ… (56 CPUs, 251.5 GB RAM, 6.3/125.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.10.12 torch-2.0.1+cu117 CUDA:0 (NVIDIA A30, 24060MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco_local.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train14\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/\u001b[0m^C\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/dataset.py\", line 100, in get_labels\n",
      "    cache, exists = np.load(str(cache_path), allow_pickle=True).item(), True  # load dict\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/coco/labels/train2017.cache'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/multiprocessing/pool.py\", line 856, in next\n",
      "    item = self._items.popleft()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/bin/yolo\", line 8, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/cfg/__init__.py\", line 304, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py\", line 297, in train\n",
      "    self.trainer.train()\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py\", line 189, in train\n",
      "    self._do_train(RANK, world_size)\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py\", line 256, in _do_train\n",
      "    self._setup_train(rank, world_size)\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py\", line 239, in _setup_train\n",
      "    self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=rank, mode='train')\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/v8/detect/train.py\", line 43, in get_dataloader\n",
      "    build_dataloader(self.args, batch_size, img_path=dataset_path, stride=gs, rank=rank, mode=mode,\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/build.py\", line 71, in build_dataloader\n",
      "    dataset = YOLODataset(\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/dataset.py\", line 44, in __init__\n",
      "    super().__init__(img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls)\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/base.py\", line 49, in __init__\n",
      "    self.labels = self.get_labels()\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/dataset.py\", line 104, in get_labels\n",
      "    cache, exists = self.cache_labels(cache_path), False  # run cache ops\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/dataset.py\", line 57, in cache_labels\n",
      "    for im_file, lb, shape, segments, keypoint, nm_f, nf_f, ne_f, nc_f, msg in pbar:\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/tqdm/std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/multiprocessing/pool.py\", line 861, in next\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/home/jgong/dev/conda/envs/ml-pytorch/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv8n on COCO8 for 3 epochs\n",
    "!yolo train model=yolov8n.pt data=coco_local.yaml epochs=1 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.10.12 torch-2.0.1+cu117 CUDA:0 (NVIDIA A30, 24060MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco_local.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/coco/labels/train2017... 0 images, 118287 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118287/118287 [01:08<00:00, 1733.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ No labels found in /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/coco/labels/train2017.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/coco/labels is not writeable, cache not saved.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "\u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/coco/labels/train2017.cache, can not start training. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m\"\u001b[39m\u001b[39myolov8n.pt\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Use the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcoco_local.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)  \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mval()  \u001b[39m# evaluate model performance on the validation set\u001b[39;00m\n\u001b[1;32m     10\u001b[0m results \u001b[39m=\u001b[39m model(\u001b[39m\"\u001b[39m\u001b[39mhttps://ultralytics.com/images/bus.jpg\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# predict on an image\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:297\u001b[0m, in \u001b[0;36mYOLO.train\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mget_model(weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, cfg\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39myaml)\n\u001b[1;32m    296\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[0;32m--> 297\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    298\u001b[0m \u001b[39m# update model and cfg after training\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m}:\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:189\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, file)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(RANK, world_size)\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:256\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, rank, world_size)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m world_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_ddp(rank, world_size)\n\u001b[0;32m--> 256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_train(rank, world_size)\n\u001b[1;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:239\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, rank, world_size)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m# dataloaders\u001b[39;00m\n\u001b[1;32m    238\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m world_size \u001b[39mif\u001b[39;00m world_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m--> 239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_dataloader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainset, batch_size\u001b[39m=\u001b[39;49mbatch_size, rank\u001b[39m=\u001b[39;49mrank, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m}:\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dataloader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestset, batch_size\u001b[39m=\u001b[39mbatch_size \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, rank\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/v8/detect/train.py:43\u001b[0m, in \u001b[0;36mDetectionTrainer.get_dataloader\u001b[0;34m(self, dataset_path, batch_size, mode, rank)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataloader\u001b[39m(\u001b[39mself\u001b[39m, dataset_path, batch_size, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, rank\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[39m# TODO: manage splits differently\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# calculate stride - check if model is initialized\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     gs \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mint\u001b[39m(de_parallel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\u001b[39m.\u001b[39mstride\u001b[39m.\u001b[39mmax() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m), \u001b[39m32\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m create_dataloader(path\u001b[39m=\u001b[39mdataset_path,\n\u001b[1;32m     29\u001b[0m                              imgsz\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mimgsz,\n\u001b[1;32m     30\u001b[0m                              batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     31\u001b[0m                              stride\u001b[39m=\u001b[39mgs,\n\u001b[1;32m     32\u001b[0m                              hyp\u001b[39m=\u001b[39m\u001b[39mvars\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs),\n\u001b[1;32m     33\u001b[0m                              augment\u001b[39m=\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m                              cache\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mcache,\n\u001b[1;32m     35\u001b[0m                              pad\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0.5\u001b[39m,\n\u001b[1;32m     36\u001b[0m                              rect\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mrect \u001b[39mor\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m                              rank\u001b[39m=\u001b[39mrank,\n\u001b[1;32m     38\u001b[0m                              workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworkers,\n\u001b[1;32m     39\u001b[0m                              close_mosaic\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mclose_mosaic \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m     40\u001b[0m                              prefix\u001b[39m=\u001b[39mcolorstr(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     41\u001b[0m                              shuffle\u001b[39m=\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     42\u001b[0m                              seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mseed)[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mv5loader \u001b[39melse\u001b[39;00m \\\n\u001b[0;32m---> 43\u001b[0m         build_dataloader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, batch_size, img_path\u001b[39m=\u001b[39;49mdataset_path, stride\u001b[39m=\u001b[39;49mgs, rank\u001b[39m=\u001b[39;49mrank, mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m     44\u001b[0m                          rect\u001b[39m=\u001b[39;49mmode \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m, names\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mnames\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/build.py:71\u001b[0m, in \u001b[0;36mbuild_dataloader\u001b[0;34m(cfg, batch, img_path, stride, rect, names, rank, mode)\u001b[0m\n\u001b[1;32m     69\u001b[0m     shuffle \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mwith\u001b[39;00m torch_distributed_zero_first(rank):  \u001b[39m# init dataset *.cache only once if DDP\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     dataset \u001b[39m=\u001b[39m YOLODataset(\n\u001b[1;32m     72\u001b[0m         img_path\u001b[39m=\u001b[39;49mimg_path,\n\u001b[1;32m     73\u001b[0m         imgsz\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mimgsz,\n\u001b[1;32m     74\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch,\n\u001b[1;32m     75\u001b[0m         augment\u001b[39m=\u001b[39;49mmode \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# augmentation\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m         hyp\u001b[39m=\u001b[39;49mcfg,  \u001b[39m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m         rect\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mrect \u001b[39mor\u001b[39;49;00m rect,  \u001b[39m# rectangular batches\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m         cache\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mcache \u001b[39mor\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     79\u001b[0m         single_cls\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49msingle_cls \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m         stride\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(stride),\n\u001b[1;32m     81\u001b[0m         pad\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m \u001b[39mif\u001b[39;49;00m mode \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     82\u001b[0m         prefix\u001b[39m=\u001b[39;49mcolorstr(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mmode\u001b[39m}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     83\u001b[0m         use_segments\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtask \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39msegment\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     84\u001b[0m         use_keypoints\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtask \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mkeypoint\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     85\u001b[0m         names\u001b[39m=\u001b[39;49mnames)\n\u001b[1;32m     87\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(batch, \u001b[39mlen\u001b[39m(dataset))\n\u001b[1;32m     88\u001b[0m nd \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()  \u001b[39m# number of CUDA devices\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/dataset.py:44\u001b[0m, in \u001b[0;36mYOLODataset.__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, use_segments, use_keypoints, names)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m names\n\u001b[1;32m     43\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_segments \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_keypoints), \u001b[39m'\u001b[39m\u001b[39mCan not use both segments and keypoints.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls)\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/base.py:49\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefix \u001b[39m=\u001b[39m prefix\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim_files \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_img_files(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_path)\n\u001b[0;32m---> 49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_labels()\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingle_cls:\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_labels(include_class\u001b[39m=\u001b[39m[])\n",
      "File \u001b[0;32m~/dev/conda/envs/ml-pytorch/lib/python3.10/site-packages/ultralytics/yolo/data/dataset.py:114\u001b[0m, in \u001b[0;36mYOLODataset.get_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         LOGGER\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(cache[\u001b[39m'\u001b[39m\u001b[39mmsgs\u001b[39m\u001b[39m'\u001b[39m]))  \u001b[39m# display warnings\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m nf \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# number of labels found\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefix\u001b[39m}\u001b[39;00m\u001b[39mNo labels found in \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m, can not start training. \u001b[39m\u001b[39m{\u001b[39;00mHELP_URL\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[39m# Read cache\u001b[39;00m\n\u001b[1;32m    117\u001b[0m [cache\u001b[39m.\u001b[39mpop(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmsgs\u001b[39m\u001b[39m'\u001b[39m)]  \u001b[39m# remove items\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /pfs/tc1/project/arcc-students/gpu_benchmarking_datasets/images/coco/labels/train2017.cache, can not start training. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"coco_local.yaml\", epochs=1)  # train the model\n",
    "metrics = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "path = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
